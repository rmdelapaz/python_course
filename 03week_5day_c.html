<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Package Management Deep Dive</title>
    <link rel="stylesheet" href="/styles/main.css">
    <link rel="icon" href="/favicon.png">
</head>
<body>
    <header>
        <h1>Python Full Stack Web Developer Course</h1>
        <h2>Week 3: Python Fundamentals (Part 2)</h2>
        <h3>Friday Morning: Package Management Deep Dive</h3>
    </header>

    <main>
        <section class="lecture_intro">
            <h2>The Foundation of Modern Development: Python Package Management</h2>
            <p>Welcome to our deep dive into Python package management! Today, we're exploring one of the most critical aspects of Python development that separates hobbyists from professionals: mastering the art and science of package management.</p>
            
            <p>As we prepare to build web applications, effective package management becomes the foundation upon which our entire development process rests. Understanding these concepts thoroughly will save you countless hours of debugging, improve collaboration with your team, and ensure your applications remain maintainable and secure.</p>
        </section>

        <section>
            <h2>The Package Management Ecosystem</h2>
            
            <p><strong>Analogy:</strong> If Python is a vast kitchen for creating culinary masterpieces, packages are pre-prepared ingredients and tools created by chefs worldwide. Package management is the inventory system that helps you source, organize, and maintain these ingredients efficiently.</p>
            
            <p>At its core, Python package management involves:</p>
            
            <ul>
                <li><strong>Discovery:</strong> Finding packages that solve your problems</li>
                <li><strong>Installation:</strong> Adding packages to your environment</li>
                <li><strong>Dependency Resolution:</strong> Ensuring all packages work together</li>
                <li><strong>Version Control:</strong> Managing package updates and compatibility</li>
                <li><strong>Distribution:</strong> Sharing your own packages with others</li>
            </ul>
            
            <p><strong>Real-world Impact:</strong> Instagram, one of the world's largest Python web applications, manages hundreds of Python packages across its infrastructure. Effective package management is what allows their team of engineers to collaborate on a codebase used by billions of people.</p>
        </section>

        <section>
            <h2>PyPI: The Python Package Index</h2>
            
            <p>The Python Package Index (PyPI) is the official repository for third-party Python packages. Think of it as the App Store or Play Store for Python software.</p>
            
            <p><strong>Key Facts:</strong></p>
            <ul>
                <li>Contains over 400,000 packages (and growing)</li>
                <li>Hosts both popular frameworks (like Django and Flask) and specialized utilities</li>
                <li>Open submission process (anyone can publish packages)</li>
                <li>Located at <a href="https://pypi.org" target="_blank">pypi.org</a></li>
            </ul>
            
            <p><strong>Browsing PyPI:</strong></p>
            <p>PyPI offers several ways to discover packages:</p>
            <ul>
                <li>Search functionality at pypi.org</li>
                <li>Browse by categories and tags</li>
                <li>View statistics like download counts</li>
                <li>See project development activity</li>
            </ul>
            
            <p><strong>Metaphor:</strong> PyPI is like a massive library where anyone can contribute books (packages), and anyone can borrow them. The quality and usefulness vary, but the collection as a whole represents one of Python's greatest strengths.</p>
        </section>

        <section>
            <h2>pip: The Standard Package Installer</h2>
            
            <p><code>pip</code> is Python's standard package installer and the primary tool most developers use to install packages from PyPI.</p>
            
            <h3>Basic pip Usage</h3>
            
            <pre><code># Installing a package
pip install requests

# Installing a specific version
pip install requests==2.28.1

# Upgrading a package
pip install --upgrade requests

# Uninstalling a package
pip uninstall requests

# Installing multiple packages from a file
pip install -r requirements.txt</code></pre>
            
            <h3>Version Specifiers</h3>
            
            <p>Understanding version specifiers is crucial for reliable package management:</p>
            
            <table>
                <tr>
                    <th>Specifier</th>
                    <th>Meaning</th>
                    <th>Example</th>
                </tr>
                <tr>
                    <td><code>==</code></td>
                    <td>Exact version</td>
                    <td><code>requests==2.28.1</code></td>
                </tr>
                <tr>
                    <td><code>>=</code></td>
                    <td>Greater than or equal to</td>
                    <td><code>requests>=2.28.1</code></td>
                </tr>
                <tr>
                    <td><code>></code></td>
                    <td>Greater than</td>
                    <td><code>requests>2.28.1</code></td>
                </tr>
                <tr>
                    <td><code><=</code></td>
                    <td>Less than or equal to</td>
                    <td><code>requests<=2.28.1</code></td>
                </tr>
                <tr>
                    <td><code><</code></td>
                    <td>Less than</td>
                    <td><code>requests<2.28.1</code></td>
                </tr>
                <tr>
                    <td><code>~=</code></td>
                    <td>Compatible release (same as <code>>=</code> current version, <code><</code> next major version)</td>
                    <td><code>requests~=2.28.1</code> (equivalent to <code>>=2.28.1, <2.29.0</code>)</td>
                </tr>
            </table>
            
            <p><strong>Analogy:</strong> Version specifiers are like recipe instructions. <code>==</code> means "use exactly 2 cups of flour," while <code>>=</code> means "use at least 2 cups of flour." The <code>~=</code> specifier is like saying "use about 2 cups of flour, but definitely not 3 cups."</p>
            
            <h3>Advanced pip Commands</h3>
            
            <pre><code># See what's installed
pip list

# Show details about a package
pip show requests

# Find outdated packages
pip list --outdated

# Download without installing
pip download requests

# Install from GitHub
pip install git+https://github.com/username/repository.git

# Install in development mode (editable)
pip install -e .</code></pre>
        </section>

        <section>
            <h2>requirements.txt: Dependency Documentation</h2>
            
            <p>The <code>requirements.txt</code> file is the standard way to document project dependencies in Python.</p>
            
            <h3>Basic Structure</h3>
            
            <pre><code># requirements.txt example
flask==2.0.1
sqlalchemy>=1.4.0,<2.0.0
requests~=2.28.1
python-dotenv==0.19.0
# Comments are supported
# You can also specify development dependencies in a separate file
</code></pre>
            
            <h3>Creating and Using requirements.txt</h3>
            
            <pre><code># Generate from current environment
pip freeze > requirements.txt

# Install from requirements file
pip install -r requirements.txt

# Combine with virtual environment activation
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt</code></pre>
            
            <h3>Best Practices</h3>
            
            <ul>
                <li><strong>Pin Versions:</strong> Use <code>==</code> for exact versions in production to ensure reproducibility</li>
                <li><strong>Separate Dev Dependencies:</strong> Maintain <code>requirements-dev.txt</code> for development tools</li>
                <li><strong>Keep Updated:</strong> Regularly review and update dependencies</li>
                <li><strong>Group and Comment:</strong> Organize related packages with comments</li>
            </ul>
            
            <h3>Real-world Example: Flask Web Application</h3>
            
            <pre><code># requirements.txt for a Flask web application

# Web Framework
flask==2.0.1
flask-wtf==1.0.0
flask-login==0.5.0

# Database
sqlalchemy==1.4.23
flask-sqlalchemy==2.5.1
flask-migrate==3.1.0
psycopg2-binary==2.9.1  # PostgreSQL driver

# API and HTTP
requests==2.28.1
urllib3==1.26.6

# Environment and Config
python-dotenv==0.19.0
pyyaml==6.0

# Security
flask-bcrypt==0.7.1
pyjwt==2.1.0

# Forms and Validation
email-validator==1.1.3
marshmallow==3.13.0</code></pre>
            
            <p><strong>Analogy:</strong> A <code>requirements.txt</code> file is like a shopping list for your application. It ensures that everyone on your team gets exactly the same ingredients, and future you doesn't forget a critical component when setting up on a new machine.</p>
        </section>

        <section>
            <h2>Understanding Dependency Resolution</h2>
            
            <p>One of the most challenging aspects of package management is dependency resolution - ensuring all packages work together harmoniously.</p>
            
            <h3>The Dependency Graph</h3>
            
            <p><strong>Metaphor:</strong> Package dependencies form a tree or graph. Your direct requirements are the trunk, their dependencies are branches, and so on to the leaves. The dependency resolver's job is to find a configuration where all packages can coexist.</p>
            
            <div class="diagram">
                <pre><code>Your Application
├── Flask 2.0.1
│   ├── Werkzeug 2.0.1
│   ├── Jinja2 3.0.1
│   │   └── MarkupSafe 2.0.1
│   ├── itsdangerous 2.0.1
│   └── click 8.0.1
└── SQLAlchemy 1.4.23</code></pre>
            </div>
            
            <h3>Dependency Hell</h3>
            
            <p>"Dependency Hell" occurs when packages have conflicting requirements:</p>
            
            <pre><code># Conflict example
PackageA requires SomeLibrary>=2.0.0
PackageB requires SomeLibrary<2.0.0

# These cannot be satisfied simultaneously!</code></pre>
            
            <p><strong>Common Resolution Strategies:</strong></p>
            <ul>
                <li><strong>Backtracking:</strong> Try different versions until a working combination is found</li>
                <li><strong>Constraint Satisfaction:</strong> Treat as a mathematical problem to solve</li>
                <li><strong>Prioritization:</strong> Prefer newer versions when possible</li>
            </ul>
            
            <h3>pip's Dependency Resolver</h3>
            
            <p>Since pip 20.3 (released in 2020), pip includes a new dependency resolver that:</p>
            <ul>
                <li>Considers all dependencies before installing anything</li>
                <li>Will backtrack and try different versions to find a working solution</li>
                <li>Fails clearly when no solution is possible</li>
            </ul>
            
            <pre><code># The new resolver may give messages like:
ERROR: Cannot install example-package because these package versions have conflicting dependencies.

The conflict is caused by:
    package-a 2.0.0 depends on somelib>=1.0.0
    package-b 3.0.0 depends on somelib<1.0.0

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip to attempt to solve the dependency conflict</code></pre>
            
            <p><strong>Real-world Example:</strong> In a machine learning project, you might face conflicts between TensorFlow, which requires a specific NumPy version range, and another data science library with different NumPy requirements. The resolver helps identify and resolve these conflicts.</p>
        </section>

        <section>
            <h2>Beyond Basic pip: Advanced Package Management Tools</h2>
            
            <p>While pip is sufficient for many projects, more complex applications can benefit from advanced tools:</p>
            
            <h3>pip-tools</h3>
            
            <p><code>pip-tools</code> provides a way to maintain pinned dependencies with more control:</p>
            
            <pre><code># Install pip-tools
pip install pip-tools

# Create a requirements.in file with high-level dependencies
# requirements.in
flask>=2.0.0
sqlalchemy

# Compile to pinned requirements.txt
pip-compile requirements.in

# Install pinned dependencies
pip install -r requirements.txt

# Update when needed
pip-compile --upgrade requirements.in</code></pre>
            
            <p><strong>Benefits:</strong></p>
            <ul>
                <li>Separates direct dependencies from transitive ones</li>
                <li>Creates deterministic builds with hashes</li>
                <li>Makes updates more predictable</li>
            </ul>
            
            <h3>conda</h3>
            
            <p><code>conda</code> is both a package manager and environment manager, popular in data science:</p>
            
            <pre><code># Create an environment
conda create --name myenv python=3.9

# Activate environment
conda activate myenv

# Install packages
conda install numpy pandas scikit-learn

# Install from specific channels
conda install -c conda-forge matplotlib

# Create environment from file
conda env create -f environment.yml</code></pre>
            
            <p><strong>Unique Features:</strong></p>
            <ul>
                <li>Handles non-Python dependencies (C/C++ libraries, etc.)</li>
                <li>Better with binary compatibility issues</li>
                <li>Particularly strong for data science packages</li>
            </ul>
            
            <p><strong>Metaphor:</strong> If pip is like a specialized kitchen supplier, conda is like a general contractor who can bring in materials and tools from anywhere, not just culinary sources.</p>
        </section>

        <section>
            <h2>Package Management in Web Development</h2>
            
            <p>Web development projects have specific package management needs and challenges:</p>
            
            <h3>Web Development Dependencies</h3>
            
            <p>Web applications typically require several categories of packages:</p>
            
            <ul>
                <li><strong>Web Frameworks:</strong> Flask, Django, FastAPI</li>
                <li><strong>Database Access:</strong> SQLAlchemy, Django ORM, psycopg2</li>
                <li><strong>Authentication:</strong> Flask-Login, Django Auth, PyJWT</li>
                <li><strong>Forms/Validation:</strong> WTForms, Pydantic</li>
                <li><strong>API Clients/Servers:</strong> Requests, Django REST Framework</li>
                <li><strong>Template Engines:</strong> Jinja2, Mako</li>
                <li><strong>Asset Management:</strong> Webassets, Django-compressor</li>
                <li><strong>Background Tasks:</strong> Celery, Huey, RQ</li>
            </ul>
            
            <h3>Development vs. Production Dependencies</h3>
            
            <p>Web projects often distinguish between different types of dependencies:</p>
            
            <pre><code># requirements-dev.txt
-r requirements.txt  # Include production dependencies

# Testing
pytest==7.0.0
pytest-flask==1.2.0
coverage==6.3.1

# Development tools
black==22.1.0  # Code formatting
flake8==4.0.1  # Linting
mypy==0.931    # Type checking
flask-debugtoolbar==0.13.1

# Documentation
sphinx==4.4.0</code></pre>
            
            <h3>Docker and Package Management</h3>
            
            <p>For containerized web applications, package management integrates with Docker:</p>
            
            <pre><code># Example Dockerfile with multi-stage build
FROM python:3.10-slim AS builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends gcc

# Copy requirements
COPY requirements.txt .

# Install dependencies
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements.txt

# Final stage
FROM python:3.10-slim

WORKDIR /app

# Copy wheels from builder stage
COPY --from=builder /app/wheels /wheels
COPY --from=builder /app/requirements.txt .

# Install dependencies
RUN pip install --no-cache /wheels/*

# Copy application code
COPY . .

CMD ["gunicorn", "app:app"]</code></pre>
            
            <p><strong>Benefits of this approach:</strong></p>
            <ul>
                <li>Smaller final image (build tools not included)</li>
                <li>Leverages Docker layer caching for faster builds</li>
                <li>Consistent, reproducible environment</li>
            </ul>
        </section>

        <section>
            <h2>Security in Package Management</h2>
            
            <p>Security is a critical aspect of package management, especially for web applications:</p>
            
            <h3>Vulnerability Management</h3>
            
            <p>Python packages can contain security vulnerabilities that need monitoring:</p>
            
            <pre><code># Check for security vulnerabilities
pip install safety
safety check -r requirements.txt

# Alternative with built-in pip audit (newer pip versions)
pip-audit</code></pre>
            
            <h3>Supply Chain Attacks</h3>
            
            <p><strong>Analogy:</strong> Supply chain attacks are like food contamination in the distribution system. The issue isn't with your cooking or your restaurant, but with an ingredient that was compromised before it reached you.</p>
            
            <p>Notable examples include:</p>
            <ul>
                <li><strong>Typosquatting:</strong> Malicious packages with names similar to popular ones</li>
                <li><strong>Dependency Confusion:</strong> Attacks targeting private package names</li>
                <li><strong>Compromised Maintainer Accounts:</strong> When legitimate package maintainers are hacked</li>
            </ul>
            
            <h3>Best Security Practices</h3>
            
            <ul>
                <li><strong>Pin Dependencies:</strong> Use exact versions in production</li>
                <li><strong>Verify Package Sources:</strong> Use trusted repositories only</li>
                <li><strong>Regular Audits:</strong> Schedule security checks</li>
                <li><strong>Hash Verification:</strong> Use <code>pip install --require-hashes -r requirements.txt</code></li>
                <li><strong>Minimal Dependencies:</strong> Only include what you need</li>
            </ul>
            
            <h3>Example: Using pip hash verification</h3>
            
            <pre><code># Generate requirements with hashes
pip-compile --generate-hashes requirements.in

# Results in a file like:
Flask==2.0.1 \
    --hash=sha256:7b2fb8e039275d8d98092bd3eb6c72920be4aeb2aca440dea70f5a9c1a800432 \
    --hash=sha256:cb90f62f1d8e4dc4621f52106613488b5ba826b2e1e10a33eac92f723093ab6a
Werkzeug==2.0.1 \
    --hash=sha256:1de1db30d010ff1af14a009224ec49ab2329ad2cde454c8a708130642d579c42 \
    --hash=sha256:6c1ec5ce6d102ddeebd4acf72ee09c9449aeded860b0ba4c2d9b02327833f5dd</code></pre>
            
            <p><strong>Real-world Impact:</strong> In 2018, a popular package (event-stream) was compromised, affecting thousands of applications, including some cryptocurrency wallets that had funds stolen. Proper hash verification would have detected the unauthorized change.</p>
        </section>

        <section>
            <h2>Creating and Distributing Your Own Packages</h2>
            
            <p>As your web development skills grow, you might create reusable components worth sharing:</p>
            
            <h3>Basic Package Structure</h3>
            
            <pre><code>my_package/
├── setup.py           # Package metadata and dependencies
├── README.md          # Documentation
├── LICENSE            # License information
├── requirements.txt   # Development dependencies
├── my_package/        # Actual package code
│   ├── __init__.py    # Makes it a package
│   ├── module1.py     # Code modules
│   └── module2.py
└── tests/             # Test code
    ├── __init__.py
    ├── test_module1.py
    └── test_module2.py</code></pre>
            
            <h3>setup.py Example</h3>
            
            <pre><code>from setuptools import setup, find_packages

setup(
    name="my-web-utils",
    version="0.1.0",
    packages=find_packages(),
    install_requires=[
        "requests>=2.25.0",
        "beautifulsoup4>=4.9.0",
    ],
    author="Your Name",
    author_email="your.email@example.com",
    description="A collection of web utilities",
    long_description=open("README.md").read(),
    long_description_content_type="text/markdown",
    url="https://github.com/yourusername/my-web-utils",
    classifiers=[
        "Programming Language :: Python :: 3",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
    python_requires=">=3.7",
)</code></pre>
            
            <h3>Building and Publishing</h3>
            
            <pre><code># Install build tools
pip install build twine

# Build the package
python -m build

# Upload to PyPI (test server first)
twine upload --repository-url https://test.pypi.org/legacy/ dist/*

# Upload to real PyPI
twine upload dist/*</code></pre>
            
            <h3>Modern Packaging with pyproject.toml</h3>
            
            <p>Python is moving toward using <code>pyproject.toml</code> instead of <code>setup.py</code>:</p>
            
            <pre><code>[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "my-web-utils"
version = "0.1.0"
authors = [
    {name = "Your Name", email = "your.email@example.com"},
]
description = "A collection of web utilities"
readme = "README.md"
requires-python = ">=3.7"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
dependencies = [
    "requests>=2.25.0",
    "beautifulsoup4>=4.9.0",
]

[project.urls]
"Homepage" = "https://github.com/yourusername/my-web-utils"
"Bug Tracker" = "https://github.com/yourusername/my-web-utils/issues"</code></pre>
            
            <p><strong>Real-world Example:</strong> Many popular web development tools like Django extensions, Flask plugins, or utility libraries started as internal tools that developers decided to share with the community.</p>
        </section>

        <section>
            <h2>Package Management in Production</h2>
            
            <p>Production deployment adds additional considerations to package management:</p>
            
            <h3>Reproducible Builds</h3>
            
            <p>Ensuring exact reproduction of environments between development and production:</p>
            
            <ul>
                <li><strong>Exact Version Pinning:</strong> All packages, including transitive dependencies</li>
                <li><strong>Hash Verification:</strong> Ensures package integrity</li>
                <li><strong>Build Artifacts:</strong> Creating wheels for faster installation</li>
            </ul>
            
            <pre><code># Creating a wheel directory
pip wheel -r requirements.txt -w ./wheels

# Installing from wheels
pip install --no-index --find-links=./wheels -r requirements.txt</code></pre>
            
            <h3>Air-Gapped Environments</h3>
            
            <p>Some production environments have no internet access:</p>
            
            <pre><code># Download all dependencies on a connected machine
pip download -r requirements.txt -d ./packages

# Transfer ./packages directory to air-gapped environment

# Install in the air-gapped environment
pip install --no-index --find-links=./packages -r requirements.txt</code></pre>
            
            <h3>Private Package Repositories</h3>
            
            <p>For proprietary code or additional security, use private repositories:</p>
            
            <ul>
                <li><strong>PyPI-compatible servers:</strong> DevPI, Artifactory, Nexus</li>
                <li><strong>Self-hosted options:</strong> GitHub/GitLab Package Registry</li>
            </ul>
            
            <pre><code># Configure pip to use private repository
pip config set global.index-url https://pypi.internal-company.com/simple

# Include credentials if needed
pip config set global.index-url https://user:pass@pypi.internal-company.com/simple</code></pre>
            
            <p><strong>Metaphor:</strong> A private PyPI server is like having your own specialty grocery store where you control exactly what ingredients are available and can add your own proprietary spice blends.</p>
        </section>

        <section>
            <h2>Practical Exercise: Building a Web Utility Package</h2>
            
            <p>Let's put our knowledge into practice by creating a simple web utility package that could be reused across projects:</p>
            
            <h3>Project: Create a Web Scraping Utility Package</h3>
            
            <ol>
                <li>Set up the project structure:
                    <pre><code>mkdir -p web_utils/web_utils
touch web_utils/web_utils/__init__.py
touch web_utils/web_utils/scraper.py
touch web_utils/web_utils/parser.py
touch web_utils/setup.py
touch web_utils/README.md
touch web_utils/LICENSE</code></pre>
                </li>
                
                <li>Create a virtual environment:
                    <pre><code>cd web_utils
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate</code></pre>
                </li>
                
                <li>Install development dependencies:
                    <pre><code>pip install requests beautifulsoup4 pytest black</code></pre>
                </li>
                
                <li>Create the scraper module (web_utils/scraper.py):
                    <pre><code>import requests
from typing import Dict, Optional

class WebScraper:
    """A simple web scraper utility."""
    
    def __init__(self, user_agent: Optional[str] = None):
        """Initialize the scraper with optional user agent."""
        self.session = requests.Session()
        if user_agent:
            self.session.headers.update({"User-Agent": user_agent})
        else:
            # Default user agent
            self.session.headers.update({
                "User-Agent": "WebUtils/1.0 (https://github.com/yourusername/web-utils)"
            })
    
    def get_page(self, url: str) -> str:
        """Get the content of a webpage as text."""
        response = self.session.get(url)
        response.raise_for_status()  # Raise exception for 4XX/5XX responses
        return response.text
    
    def get_json(self, url: str, params: Optional[Dict] = None) -> Dict:
        """Get JSON data from an API endpoint."""
        response = self.session.get(url, params=params)
        response.raise_for_status()
        return response.json()
    
    def download_file(self, url: str, local_path: str) -> None:
        """Download a file from a URL to a local path."""
        with self.session.get(url, stream=True) as response:
            response.raise_for_status()
            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)</code></pre>
                </li>
                
                <li>Create the parser module (web_utils/parser.py):
                    <pre><code>from bs4 import BeautifulSoup
from typing import List, Dict, Optional

class HtmlParser:
    """A utility for parsing HTML content."""
    
    @staticmethod
    def extract_links(html_content: str, base_url: Optional[str] = None) -> List[Dict]:
        """Extract all links from an HTML document.
        
        Args:
            html_content: HTML content as string
            base_url: Optional base URL to resolve relative URLs
            
        Returns:
            List of dictionaries with 'text' and 'url' keys
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        links = []
        
        for a_tag in soup.find_all('a', href=True):
            url = a_tag['href']
            # Resolve relative URLs if base_url is provided
            if base_url and url.startswith('/'):
                url = base_url.rstrip('/') + url
                
            links.append({
                'text': a_tag.get_text(strip=True),
                'url': url
            })
            
        return links
    
    @staticmethod
    def extract_text(html_content: str, selector: str) -> List[str]:
        """Extract text content matching a CSS selector.
        
        Args:
            html_content: HTML content as string
            selector: CSS selector to match elements
            
        Returns:
            List of text strings from matching elements
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        elements = soup.select(selector)
        return [element.get_text(strip=True) for element in elements]
    
    @staticmethod
    def extract_table(html_content: str, table_selector: str = "table") -> List[Dict]:
        """Extract data from an HTML table into a list of dictionaries.
        
        Args:
            html_content: HTML content as string
            table_selector: CSS selector to find the table
            
        Returns:
            List of dictionaries with column names as keys
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        table = soup.select_one(table_selector)
        
        if not table:
            return []
            
        rows = table.find_all('tr')
        if not rows:
            return []
            
        # Extract headers
        headers = [th.get_text(strip=True) for th in rows[0].find_all(['th', 'td'])]
        
        # Extract data rows
        data = []
        for row in rows[1:]:
            cells = row.find_all(['td', 'th'])
            if len(cells) == len(headers):
                row_data = {}
                for i, cell in enumerate(cells):
                    row_data[headers[i]] = cell.get_text(strip=True)
                data.append(row_data)
                
        return data</code></pre>
                </li>
                
                <li>Update the __init__.py file to expose the classes:
                    <pre><code>from .scraper import WebScraper
from .parser import HtmlParser

__version__ = "0.1.0"</code></pre>
                </li>
                
                <li>Create setup.py:
                    <pre><code>from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name="web-utils",
    version="0.1.0",
    author="Your Name",
    author_email="your.email@example.com",
    description="Utility functions for web scraping and parsing",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/yourusername/web-utils",
    packages=find_packages(),
    classifiers=[
        "Programming Language :: Python :: 3",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
    python_requires=">=3.7",
    install_requires=[
        "requests>=2.25.0",
        "beautifulsoup4>=4.9.0",
    ],
)</code></pre>
                </li>
                
                <li>Create a basic README.md:
                    <pre><code># Web Utils

A collection of utilities for web scraping and HTML parsing.

## Installation

```
pip install web-utils
```

## Usage

```python
from web_utils import WebScraper, HtmlParser

# Create a scraper
scraper = WebScraper()

# Get a web page
html = scraper.get_page("https://example.com")

# Extract all links
parser = HtmlParser()
links = parser.extract_links(html)
for link in links:
    print(f"{link['text']}: {link['url']}")

# Extract data from a table
table_data = parser.extract_table(html)
print(table_data)
```

## License

MIT
</code></pre>
                </li>
                
                <li>Install the package in development mode:
                    <pre><code>pip install -e .</code></pre>
                </li>
                
                <li>Build the package:
                    <pre><code>pip install build
python -m build</code></pre>
                </li>
            </ol>
            
            <p>This exercise demonstrates:</p>
            <ul>
                <li>Creating a reusable package</li>
                <li>Setting up the proper structure</li>
                <li>Managing dependencies</li>
                <li>Building distribution files</li>
            </ul>
            
            <p><strong>Real-world Application:</strong> This pattern is how libraries like <code>requests-html</code>, <code>newspaper3k</code>, and other specialized web utilities are structured. These tools can save you significant time in future web projects.</p>
        </section>

        <section>
            <h2>Conclusion and Best Practices</h2>
            
            <p>As we've explored, package management is a fundamental skill for Python web developers. To wrap up, here are key best practices to follow:</p>
            
            <h3>Package Management Checklist</h3>
            
            <ul>
                <li><strong>Always Use Virtual Environments:</strong> Isolate project dependencies</li>
                <li><strong>Document Dependencies:</strong> Maintain up-to-date requirements files</li>
                <li><strong>Pin Versions in Production:</strong> Use exact versions (<code>==</code>) for reproducibility</li>
                <li><strong>Regularly Update Dependencies:</strong> Stay current with security patches</li>
                <li><strong>Minimize Dependencies:</strong> Only include what you need</li>
                <li><strong>Audit Security:</strong> Check for vulnerabilities regularly</li>
                <li><strong>Separate Dev Dependencies:</strong> Distinguish between production and development needs</li>
                <li><strong>Consider Build Tools:</strong> Use <code>pip-tools</code> or similar for more control</li>
                <li><strong>Lock Dependencies:</strong> Ensure consistency across environments</li>
            </ul>
            
            <h3>Moving Forward</h3>
            
            <p>As we continue our journey into web development with Python, effective package management will be a recurring theme. The concepts we've covered today will apply to Flask, Django, and all other web frameworks we'll explore.</p>
            
            <p>In the next sessions, we'll build on this foundation as we dive into specific web development topics, where we'll encounter and utilize many of the packages we've discussed today.</p>
        </section>

        <section class="resources">
            <h2>Additional Resources</h2>
            <ul>
                <li><a href="https://pip.pypa.io/en/stable/" target="_blank">pip documentation</a></li>
                <li><a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/" target="_blank">Python Packaging User Guide</a></li>
                <li><a href="https://github.com/pypa/sampleproject" target="_blank">Sample Python Package</a></li>
                <li><a href="https://pypi.org" target="_blank">Python Package Index (PyPI)</a></li>
                <li><a href="https://pip-tools.readthedocs.io/en/latest/" target="_blank">pip-tools documentation</a></li>
                <li><a href="https://github.com/pyupio/safety" target="_blank">Safety - Python Vulnerability Scanner</a></li>
                <li><a href="https://nvd.nist.gov/vuln/search" target="_blank">National Vulnerability Database</a></li>
                <li><a href="https://12factor.net/dependencies" target="_blank">The Twelve-Factor App - Dependencies</a></li>
            </ul>
        </section>
    </main>

    <footer>
        <p>Python Full Stack Developer Course - File: week3_friday_package_management.html</p>
        <p>Located in course root directory</p>
    </footer>
</body>
</html>
