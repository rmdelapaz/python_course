<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Docker Basics & Containerization</title>
    <link rel="stylesheet" href="/styles/main.css">
    <link rel="icon" href="/favicon.png">
</head>
<body>
    <header>
        <h1>Docker Basics & Containerization</h1>
        <p class="subtitle">Week 1 - Wednesday: Full Stack Web Development with Python</p>
    </header>

    <main>
        <section>
            <h2>Introduction to Containerization</h2>
            <p>Imagine moving to a new house. You could transport your belongings in random bags and boxes of different sizes, creating a chaotic moving process. Or, you could use standardized shipping containers that fit perfectly on trucks, trains, and ships. Containerization in software follows a similar principle—packaging applications and their dependencies in a standardized way that works consistently across different environments.</p>
            
            <p>Before containerization, deploying applications was often painful and unpredictable. Developers would encounter the dreaded "it works on my machine" problem, where code ran perfectly in development but failed in production due to subtle environmental differences. Containerization solves this by bundling an application with everything it needs to run correctly, creating a consistent environment from development through production.</p>
            
            <h3>The Evolution of Application Deployment</h3>
            <ul>
                <li><strong>Traditional Deployment</strong>: Applications running directly on physical servers, with high resource inefficiency and complex dependency management</li>
                <li><strong>Virtual Machines</strong>: Multiple isolated operating systems on one physical server, improving efficiency but still heavyweight</li>
                <li><strong>Containers</strong>: Lightweight, portable environments that share the host's OS kernel while maintaining isolation</li>
            </ul>
            
            <p>The container revolution has transformed how applications are developed, tested, and deployed, making it an essential skill for modern web developers.</p>
        </section>

        <section>
            <h2>Understanding Docker</h2>
            
            <p>Docker is the most popular containerization platform, providing tools that enable developers to easily build, deploy, and run applications in containers. Think of Docker as a standardized shipping system for code.</p>
            
            <h3>What Problems Does Docker Solve?</h3>
            
            <h4>The "Works on My Machine" Problem</h4>
            <p>We've all experienced this situation: code works perfectly on one developer's machine but fails on another's or in production. Docker solves this by ensuring consistency across environments.</p>
            
            <h4>Environment Parity</h4>
            <p>Development, testing, staging, and production environments should be as similar as possible. Docker makes this easy by using the same container images across environments.</p>
            
            <h4>Dependency Management</h4>
            <p>Different applications may require different versions of libraries or runtimes. Docker isolates these dependencies, preventing conflicts.</p>
            
            <h4>Resource Efficiency</h4>
            <p>Unlike virtual machines that require a full OS for each instance, containers share the host OS kernel, making them lightweight and efficient.</p>
            
            <h4>Application Isolation</h4>
            <p>Containers provide process isolation without the overhead of virtual machines, allowing applications to run side by side without interference.</p>
            
            <h3>Docker's Core Philosophy</h3>
            <p>Docker embodies several key principles:</p>
            <ul>
                <li><strong>Build once, run anywhere</strong>: Create a container image once and run it on any Docker-compatible system</li>
                <li><strong>Immutable infrastructure</strong>: Containers should be treated as immutable—instead of modifying containers, create new ones</li>
                <li><strong>Microservices architecture</strong>: Break applications into smaller, focused containers that work together</li>
                <li><strong>Declarative configuration</strong>: Infrastructure defined as code, making it reproducible and version-controlled</li>
            </ul>
        </section>

        <section>
            <h2>Docker Architecture and Components</h2>
            
            <p>Docker uses a client-server architecture with several key components working together:</p>
            
            <h3>Docker Engine</h3>
            <p>The core of Docker, consisting of:</p>
            <ul>
                <li><strong>Docker Daemon (dockerd)</strong>: A background service that manages Docker objects like images, containers, networks, and volumes</li>
                <li><strong>REST API</strong>: An interface that programs can use to talk to the daemon</li>
                <li><strong>Docker CLI</strong>: Command-line interface for interacting with Docker</li>
            </ul>
            
            <h3>Docker Objects</h3>
            
            <h4>Images</h4>
            <p>A Docker image is a read-only template containing instructions for creating a Docker container. Think of it as a snapshot or blueprint of an application and its environment. Images are often based on other images with additional customization.</p>
            
            <p>For example, you might start with a Python base image, then add your application code, specific Python packages, and configuration files to create your custom image.</p>
            
            <h4>Containers</h4>
            <p>A container is a runnable instance of an image—what the image becomes in memory when executed. You can create, start, stop, move, or delete containers using the Docker API or CLI.</p>
            
            <p>Containers are:</p>
            <ul>
                <li><strong>Isolated</strong>: Each container has its own filesystem, CPU, memory, process space, and more</li>
                <li><strong>Portable</strong>: Can run anywhere Docker runs, regardless of underlying infrastructure</li>
                <li><strong>Lightweight</strong>: Share the host kernel rather than including a full OS</li>
            </ul>
            
            <h4>Volumes</h4>
            <p>Persistent data storage mechanisms managed by Docker. Volumes are completely independent of the container lifecycle, allowing data to persist even when containers are removed.</p>
            
            <h4>Networks</h4>
            <p>Docker's networking subsystem that allows containers to communicate with each other and with the outside world.</p>
            
            <h3>Docker Registry</h3>
            <p>A registry stores Docker images. Docker Hub is a public registry that anyone can use, but many organizations set up private registries. When you run <code>docker pull</code> or <code>docker run</code>, the required images are pulled from your configured registry.</p>
        </section>

        <section>
            <h2>Installing Docker</h2>
            
            <p>Before we can start using Docker, we need to install it on our system. Docker Desktop provides a user-friendly package that includes the Docker Engine, Docker CLI, Docker Compose, and other tools.</p>
            
            <h3>Installation Steps</h3>
            
            <h4>For Windows</h4>
            <ol>
                <li>Visit <a href="https://www.docker.com/products/docker-desktop" target="_blank">Docker Desktop</a> and download the Windows installer</li>
                <li>Double-click the installer to run it</li>
                <li>Follow the installation wizard</li>
                <li>Docker Desktop will start automatically after installation</li>
            </ol>
            <p>Note: Windows 10/11 Home users will need to enable WSL 2 (Windows Subsystem for Linux). Docker Desktop will guide you through this process.</p>
            
            <h4>For macOS</h4>
            <ol>
                <li>Visit <a href="https://www.docker.com/products/docker-desktop" target="_blank">Docker Desktop</a> and download the macOS installer (.dmg)</li>
                <li>Double-click the .dmg file</li>
                <li>Drag Docker to your Applications folder</li>
                <li>Open Docker from your Applications folder</li>
            </ol>
            <p>Note: Docker Desktop for macOS is available for both Intel and Apple Silicon processors.</p>
            
            <h4>For Linux</h4>
            <p>Docker Desktop is available for certain Linux distributions, but you can also install Docker Engine directly. Here's a generic process for Ubuntu:</p>
            <pre><code># Update package index
sudo apt-get update

# Install packages to allow apt to use a repository over HTTPS
sudo apt-get install apt-transport-https ca-certificates curl software-properties-common

# Add Docker's official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

# Set up the stable repository
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

# Update package index again
sudo apt-get update

# Install the latest version of Docker Engine and containerd
sudo apt-get install docker-ce docker-ce-cli containerd.io

# Verify installation by running a hello-world container
sudo docker run hello-world</code></pre>
            
            <h3>Verifying Your Installation</h3>
            <p>To verify that Docker is installed correctly, open a terminal or command prompt and run:</p>
            <pre><code>docker --version
docker run hello-world</code></pre>
            
            <p>The hello-world container is a simple test image that confirms Docker is working correctly by displaying a message and exiting.</p>
        </section>

        <section>
            <h2>Basic Docker Commands</h2>
            
            <p>Now that we have Docker installed, let's learn some essential commands to manage images and containers.</p>
            
            <h3>Working with Images</h3>
            
            <h4>Pulling Images</h4>
            <p>To download an image from a registry (like Docker Hub):</p>
            <pre><code>docker pull python:3.10-slim</code></pre>
            
            <p>This command downloads the Python 3.10 slim image, which is a lightweight version of Python 3.10.</p>
            
            <h4>Listing Images</h4>
            <p>To see what images are available on your system:</p>
            <pre><code>docker images</code></pre>
            
            <h4>Searching for Images</h4>
            <p>To search Docker Hub for images:</p>
            <pre><code>docker search nginx</code></pre>
            
            <h3>Working with Containers</h3>
            
            <h4>Running Containers</h4>
            <p>To start a new container from an image:</p>
            <pre><code>docker run python:3.10-slim python -c "print('Hello from Python!')"</code></pre>
            
            <p>This command:</p>
            <ol>
                <li>Pulls the python:3.10-slim image if it's not already available locally</li>
                <li>Creates and starts a new container from that image</li>
                <li>Runs the command <code>python -c "print('Hello from Python!')"</code> inside the container</li>
                <li>Displays the output</li>
                <li>Exits the container</li>
            </ol>
            
            <h4>Common docker run Options</h4>
            <pre><code># Run container in the background (detached mode)
docker run -d nginx

# Assign a name to the container
docker run --name my-python-app python:3.10-slim

# Map a port from the container to the host
docker run -p 8080:80 nginx

# Mount a volume
docker run -v /host/path:/container/path python:3.10-slim

# Set environment variables
docker run -e VARIABLE_NAME=value python:3.10-slim

# Run container interactively
docker run -it python:3.10-slim bash</code></pre>
            
            <h4>Listing Containers</h4>
            <pre><code># List running containers
docker ps

# List all containers (including stopped ones)
docker ps -a</code></pre>
            
            <h4>Container Lifecycle Commands</h4>
            <pre><code># Stop a running container
docker stop container_id_or_name

# Start a stopped container
docker start container_id_or_name

# Restart a container
docker restart container_id_or_name

# Remove a container (must be stopped first)
docker rm container_id_or_name

# Force remove a running container
docker rm -f container_id_or_name</code></pre>
            
            <h4>Container Information and Logs</h4>
            <pre><code># View logs from a container
docker logs container_id_or_name

# Follow log output in real time
docker logs -f container_id_or_name

# Show detailed container information
docker inspect container_id_or_name</code></pre>
            
            <h4>Executing Commands in Running Containers</h4>
            <pre><code># Run a command in a running container
docker exec container_id_or_name command

# Get an interactive shell in a running container
docker exec -it container_id_or_name bash</code></pre>
            
            <h3>Cleaning Up</h3>
            <pre><code># Remove all stopped containers
docker container prune

# Remove unused images
docker image prune

# Remove all unused objects (containers, images, networks, volumes)
docker system prune</code></pre>
        </section>

        <section>
            <h2>Creating Your First Dockerfile</h2>
            
            <p>A Dockerfile is a text file that contains instructions for building a Docker image. Think of it as a recipe for creating your application environment.</p>
            
            <h3>Dockerfile Basics</h3>
            <p>Here's a simple Dockerfile for a Python web application:</p>
            
            <pre><code># Use an official Python runtime as a base image
FROM python:3.10-slim

# Set the working directory in the container
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY . /app/

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Make port 5000 available to the world outside this container
EXPOSE 5000

# Define environment variable
ENV NAME World

# Run app.py when the container launches
CMD ["python", "app.py"]</code></pre>
            
            <h3>Key Dockerfile Instructions</h3>
            
            <h4>FROM</h4>
            <p>Specifies the base image to use. Every Dockerfile must start with a FROM instruction.</p>
            <pre><code>FROM python:3.10-slim</code></pre>
            
            <h4>WORKDIR</h4>
            <p>Sets the working directory for subsequent instructions. If the directory doesn't exist, it will be created.</p>
            <pre><code>WORKDIR /app</code></pre>
            
            <h4>COPY and ADD</h4>
            <p>Copies files from the host to the container filesystem. ADD is similar but has additional features like URL support and automatic tar extraction.</p>
            <pre><code>COPY requirements.txt /app/
COPY . /app/</code></pre>
            
            <h4>RUN</h4>
            <p>Executes commands in a new layer on top of the current image and commits the results.</p>
            <pre><code>RUN pip install --no-cache-dir -r requirements.txt</code></pre>
            
            <h4>EXPOSE</h4>
            <p>Informs Docker that the container listens on the specified network ports at runtime. This doesn't actually publish the port.</p>
            <pre><code>EXPOSE 5000</code></pre>
            
            <h4>ENV</h4>
            <p>Sets environment variables that will be available to processes running inside the container.</p>
            <pre><code>ENV FLASK_ENV=production</code></pre>
            
            <h4>CMD</h4>
            <p>Provides defaults for executing a container. There can only be one CMD instruction in a Dockerfile.</p>
            <pre><code>CMD ["python", "app.py"]</code></pre>
            
            <h4>ENTRYPOINT</h4>
            <p>Configures a container to run as an executable. When used with CMD, ENTRYPOINT defines the command and CMD provides the arguments.</p>
            <pre><code>ENTRYPOINT ["python"]
CMD ["app.py"]</code></pre>
            
            <h3>Building an Image from a Dockerfile</h3>
            <p>Once you've created a Dockerfile, you can build an image using the <code>docker build</code> command:</p>
            <pre><code>docker build -t my-python-app .</code></pre>
            
            <p>This command builds an image from the Dockerfile in the current directory (.) and tags (-t) it with the name "my-python-app".</p>
            
            <h3>Building Efficient Docker Images</h3>
            <p>Here are some best practices for creating efficient Docker images:</p>
            
            <h4>Use Specific Base Images</h4>
            <p>Be specific with your base image tags (e.g., <code>python:3.10-slim</code> instead of just <code>python</code>). This ensures consistency and prevents unexpected changes when rebuilding.</p>
            
            <h4>Leverage the Docker Cache</h4>
            <p>Docker caches build steps to speed up subsequent builds. Order your Dockerfile instructions from least to most likely to change:</p>
            <pre><code># Install dependencies first (changes less frequently)
COPY requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt

# Then copy the rest of your application code (changes more frequently)
COPY . /app/</code></pre>
            
            <h4>Minimize Layers</h4>
            <p>Each RUN, COPY, and ADD instruction creates a new layer in your image. Combine related commands to reduce layers:</p>
            <pre><code># Instead of this (creates 3 layers):
RUN apt-get update
RUN apt-get install -y package1
RUN apt-get clean

# Do this (creates 1 layer):
RUN apt-get update && \
    apt-get install -y package1 && \
    apt-get clean</code></pre>
            
            <h4>Clean Up in the Same Layer</h4>
            <p>Clean up any temporary files in the same layer where they were created:</p>
            <pre><code>RUN apt-get update && \
    apt-get install -y gcc && \
    # ... build something with gcc ... && \
    apt-get remove -y gcc && \
    apt-get autoremove -y && \
    apt-get clean</code></pre>
            
            <h4>Use .dockerignore</h4>
            <p>Create a .dockerignore file to exclude files and directories from the build context, similar to .gitignore:</p>
            <pre><code># .dockerignore
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.git/
.idea/
.vscode/
*.swp
*.swo</code></pre>
        </section>

        <section>
            <h2>Running Your Docker Container</h2>
            
            <h3>Basic Container Execution</h3>
            <p>After building your image, you can run it as a container:</p>
            <pre><code>docker run my-python-app</code></pre>
            
            <h3>Interactive Mode</h3>
            <p>To interact with your container (e.g., to access a shell):</p>
            <pre><code>docker run -it my-python-app bash</code></pre>
            
            <h3>Port Mapping</h3>
            <p>To access a web application running inside your container, map container ports to host ports:</p>
            <pre><code>docker run -p 8080:5000 my-python-app</code></pre>
            
            <p>This maps port 5000 in the container to port 8080 on your host machine, so you can access the application at http://localhost:8080.</p>
            
            <h3>Volume Mounting</h3>
            <p>To persist data or share files between your host and container:</p>
            <pre><code>docker run -v /host/path:/container/path my-python-app</code></pre>
            
            <p>This mounts /host/path from your machine to /container/path in the container. Any changes to files in this directory will be reflected in both places.</p>
            
            <h3>Environment Variables</h3>
            <p>Pass environment variables to configure your application:</p>
            <pre><code>docker run -e DEBUG=True -e DB_HOST=localhost my-python-app</code></pre>
            
            <h3>Detached Mode</h3>
            <p>Run containers in the background:</p>
            <pre><code>docker run -d my-python-app</code></pre>
            
            <p>You can see running containers with <code>docker ps</code> and view logs with <code>docker logs [container_id]</code>.</p>
            
            <h3>Container Names</h3>
            <p>Assign a name to your container for easier reference:</p>
            <pre><code>docker run --name my-app-instance my-python-app</code></pre>
            
            <h3>Example: Running a Python Flask Application</h3>
            <p>Let's put it all together with a complete example of a Flask web application:</p>
            
            <h4>1. Create a simple Flask application (app.py)</h4>
            <pre><code>from flask import Flask
import os

app = Flask(__name__)

@app.route('/')
def hello():
    name = os.environ.get('NAME', 'World')
    return f'Hello, {name}!'

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)</code></pre>
            
            <h4>2. Create requirements.txt</h4>
            <pre><code>flask==2.0.1</code></pre>
            
            <h4>3. Create a Dockerfile</h4>
            <pre><code>FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5000

ENV NAME World

CMD ["python", "app.py"]</code></pre>
            
            <h4>4. Build the image</h4>
            <pre><code>docker build -t flask-hello-world .</code></pre>
            
            <h4>5. Run the container</h4>
            <pre><code>docker run -p 5000:5000 --name flask-app flask-hello-world</code></pre>
            
            <p>Now you can access your Flask application at http://localhost:5000. You can customize the greeting by setting the NAME environment variable:</p>
            
            <pre><code>docker run -p 5000:5000 -e NAME="Docker Learner" --name flask-app flask-hello-world</code></pre>
        </section>

        <section>
            <h2>Docker Hub and Public Images</h2>
            
            <p>Docker Hub is a cloud-based registry service that allows you to share and manage Docker images. It serves as both a public repository for official images and a platform for storing your own images.</p>
            
            <h3>Using Official Images</h3>
            <p>Docker Hub hosts official images for popular software like Python, Node.js, PostgreSQL, Redis, and many others. These images are maintained by the Docker team or the software maintainers and follow best practices for security and usage.</p>
            
            <p>To use an official image, simply pull it from Docker Hub:</p>
            <pre><code>docker pull python:3.10-slim</code></pre>
            
            <h3>Exploring Docker Hub</h3>
            <ol>
                <li>Visit <a href="https://hub.docker.com" target="_blank">hub.docker.com</a> and create an account if you don't already have one</li>
                <li>Browse official images and community images</li>
                <li>Check image details including pull commands, tags, and documentation</li>
            </ol>
            
            <h3>Pushing Your Images to Docker Hub</h3>
            <p>Sharing your images on Docker Hub allows you to easily distribute your applications or use them across different environments.</p>
            
            <h4>1. Log in to Docker Hub from your terminal</h4>
            <pre><code>docker login</code></pre>
            
            <h4>2. Tag your image with your Docker Hub username</h4>
            <pre><code>docker tag my-python-app yourusername/my-python-app:latest</code></pre>
            
            <h4>3. Push the image to Docker Hub</h4>
            <pre><code>docker push yourusername/my-python-app:latest</code></pre>
            
            <h3>Image Tagging Best Practices</h3>
            <p>Tags help you manage different versions of your images:</p>
            <ul>
                <li><strong>latest</strong>: Typically points to the most recent version</li>
                <li><strong>Semantic versioning</strong>: Use version numbers like 1.0.0, 2.1.3</li>
                <li><strong>Feature tags</strong>: Use descriptive tags like slim, alpine, dev, prod</li>
            </ul>
            
            <pre><code># Tag with version and variant
docker tag my-app yourusername/my-app:1.0.0-slim

# Tag as latest
docker tag my-app yourusername/my-app:latest</code></pre>
        </section>

        <section>
            <h2>Python Development with Docker</h2>
            
            <p>Docker is particularly valuable for Python development because it solves many common Python environment issues:</p>
            
            <h3>Benefits for Python Development</h3>
            <ul>
                <li><strong>Dependency isolation</strong>: Each project can have its own dependencies without conflicts</li>
                <li><strong>Python version management</strong>: Run different Python versions for different projects</li>
                <li><strong>Consistent environments</strong>: Everyone on the team has the same setup, eliminating "works on my machine" problems</li>
                <li><strong>Simple onboarding</strong>: New team members can get started with a single docker command</li>
            </ul>
            
            <h3>Python-Specific Docker Best Practices</h3>
            
            <h4>Use Appropriate Base Images</h4>
            <p>Python has several official Docker images with different sizes and purposes:</p>
            <ul>
                <li><strong>python:3.10</strong>: Full Python installation with development tools (large)</li>
                <li><strong>python:3.10-slim</strong>: Minimal Python installation (medium)</li>
                <li><strong>python:3.10-alpine</strong>: Ultra-minimal Python using Alpine Linux (smallest)</li>
            </ul>
            
            <p>For most web development, the slim variant provides a good balance of size and functionality.</p>
            
            <h4>Managing Dependencies</h4>
            <p>A common pattern for Python applications:</p>
            <pre><code>FROM python:3.10-slim

WORKDIR /app

# Copy and install requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Then copy the rest of the application
COPY . .</code></pre>
            
            <h4>Python-Specific Optimizations</h4>
            <pre><code># Prevent Python from writing .pyc files
ENV PYTHONDONTWRITEBYTECODE=1

# Prevent Python from buffering stdout and stderr
ENV PYTHONUNBUFFERED=1</code></pre>
            
            <h3>Development Workflow with Python and Docker</h3>
            
            <h4>Using Volume Mounts for Live Code Changes</h4>
            <p>Mount your code directory into the container to see changes immediately without rebuilding:</p>
            <pre><code>docker run -v $(pwd):/app -p 5000:5000 my-python-app</code></pre>
            
            <h4>Debugging Python in Containers</h4>
            <p>For interactive debugging:</p>
            <ol>
                <li>Ensure your app is configured to listen on 0.0.0.0 (not just localhost)</li>
                <li>Mount your code as a volume</li>
                <li>Use the -it flag for interactive mode</li>
            </ol>
            
            <pre><code>docker run -it -v $(pwd):/app -p 5000:5000 my-python-app python -m debugpy --listen 0.0.0.0:5678 app.py</code></pre>
            
            <p>Then connect your IDE's debugger to port 5678.</p>
            
            <h4>Managing Python Packages</h4>
            <p>Use a requirements.txt file or Pipenv to manage dependencies consistently:</p>
            <pre><code># For pip with requirements.txt
FROM python:3.10-slim
COPY requirements.txt .
RUN pip install -r requirements.txt

# For Pipenv
FROM python:3.10-slim
RUN pip install pipenv
COPY Pipfile Pipfile.lock .
RUN pipenv install --system --deploy</code></pre>
        </section>

        <section>
            <h2>Real-World Docker Examples</h2>
            
            <h3>Multi-Stage Builds</h3>
            <p>Multi-stage builds allow you to use one image for building and another for running your application, resulting in smaller final images:</p>
            
            <pre><code># Build stage
FROM python:3.10 AS builder

WORKDIR /app

COPY requirements.txt .
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements.txt

# Final stage
FROM python:3.10-slim

WORKDIR /app

# Copy built wheels from builder stage
COPY --from=builder /app/wheels /wheels
RUN pip install --no-cache /wheels/*

COPY . .

CMD ["python", "app.py"]</code></pre>
            
            <h3>Python Web Application with Database</h3>
            <p>A more complete example with a Flask application and PostgreSQL database:</p>
            
            <pre><code># Dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

ENV FLASK_APP=app.py
ENV DATABASE_URL=postgresql://postgres:postgres@db:5432/mydatabase

EXPOSE 5000

CMD ["flask", "run", "--host=0.0.0.0"]</code></pre>
            
            <p>To run this with a PostgreSQL database, you'd use Docker Compose (which we'll cover tomorrow).</p>
            
            <h3>Development vs. Production Configurations</h3>
            <p>You can create different Docker configurations for development and production:</p>
            
            <h4>Development (Dockerfile.dev)</h4>
            <pre><code>FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Don't copy code, it will be mounted as a volume
# COPY . .

ENV FLASK_APP=app.py
ENV FLASK_ENV=development
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

EXPOSE 5000

CMD ["flask", "run", "--host=0.0.0.0", "--reload"]</code></pre>
            
            <h4>Production (Dockerfile.prod)</h4>
            <pre><code>FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

ENV FLASK_APP=app.py
ENV FLASK_ENV=

<h4>Production (Dockerfile.prod)</h4>
<pre><code>FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

ENV FLASK_APP=app.py
ENV FLASK_ENV=production

EXPOSE 5000

# Run gunicorn for production
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "app:app"]</code></pre>
        </section>

        <section>
            <h2>Docker Networking Basics</h2>
            
            <p>Docker provides built-in networking capabilities that allow containers to communicate with each other and with the outside world. Understanding Docker networking is crucial for building multi-container applications.</p>
            
            <h3>Network Types</h3>
            <ul>
                <li><strong>bridge</strong>: The default network. Containers on the same bridge network can communicate with each other.</li>
                <li><strong>host</strong>: Removes network isolation between the container and the host. The container uses the host's networking directly.</li>
                <li><strong>none</strong>: Disables networking for the container.</li>
                <li><strong>overlay</strong>: Connects multiple Docker daemons together, enabling swarm services to communicate.</li>
                <li><strong>macvlan</strong>: Assigns a MAC address to a container, making it appear as a physical device on your network.</li>
                <li><strong>custom networks</strong>: User-defined networks with more control over network properties.</li>
            </ul>
            
            <h3>Basic Network Commands</h3>
            <pre><code># List networks
docker network ls

# Inspect a network
docker network inspect bridge

# Create a custom network
docker network create my-network

# Run a container connected to a specific network
docker run --network=my-network my-python-app

# Connect a running container to a network
docker network connect my-network container_id_or_name

# Disconnect a container from a network
docker network disconnect my-network container_id_or_name</code></pre>
            
            <h3>Container Communication</h3>
            <p>Containers on the same network can communicate using container names as hostnames. For example, if you have two containers named "web" and "db" on the same network, the "web" container can connect to the "db" container using "db" as the hostname.</p>
            
            <pre><code># Create a network
docker network create app-network

# Run a database container
docker run --name db --network app-network -e POSTGRES_PASSWORD=secret postgres

# Run a web app container that connects to the database
docker run --name web --network app-network -e DATABASE_URL=postgres://postgres:secret@db:5432/postgres my-python-app</code></pre>
        </section>

        <section>
            <h2>Volume Management</h2>
            
            <p>Docker volumes are the preferred mechanism for persisting data generated by and used by Docker containers. They are completely managed by Docker and offer several advantages over bind mounts.</p>
            
            <h3>Types of Data Storage in Docker</h3>
            <ul>
                <li><strong>Volumes</strong>: Created and managed by Docker, stored in a part of the host filesystem that's managed by Docker.</li>
                <li><strong>Bind mounts</strong>: A file or directory on the host machine mounted into a container.</li>
                <li><strong>tmpfs mounts</strong>: Stored in the host system's memory only, never written to the host filesystem.</li>
            </ul>
            
            <h3>Working with Volumes</h3>
            <pre><code># Create a volume
docker volume create my-data

# List volumes
docker volume ls

# Inspect a volume
docker volume inspect my-data

# Remove a volume
docker volume rm my-data

# Remove all unused volumes
docker volume prune</code></pre>
            
            <h3>Using Volumes with Containers</h3>
            <pre><code># Run a container with a named volume
docker run -v my-data:/app/data my-python-app

# Run a container with an anonymous volume
docker run -v /app/data my-python-app

# Run a container with a bind mount
docker run -v /host/path:/container/path my-python-app</code></pre>
            
            <h3>Data Persistence Scenarios</h3>
            
            <h4>Database Data</h4>
            <pre><code>docker run -v postgres-data:/var/lib/postgresql/data postgres</code></pre>
            
            <h4>Development Code</h4>
            <pre><code>docker run -v $(pwd):/app my-python-app</code></pre>
            
            <h4>Configuration Files</h4>
            <pre><code>docker run -v $(pwd)/config.ini:/app/config.ini my-python-app</code></pre>
        </section>

        <section>
            <h2>Troubleshooting Common Docker Issues</h2>
            
            <p>As with any technology, you'll encounter challenges when working with Docker. Here are some common issues and how to resolve them:</p>
            
            <h3>Container Won't Start</h3>
            <p>If your container exits immediately after starting:</p>
            <ol>
                <li>Check the logs: <code>docker logs container_id_or_name</code></li>
                <li>Ensure your CMD or ENTRYPOINT is correct</li>
                <li>Verify that your application is properly configured to run in a container (e.g., listening on 0.0.0.0 instead of localhost)</li>
                <li>Try running in interactive mode: <code>docker run -it your-image bash</code></li>
            </ol>
            
            <h3>Can't Access Container Service</h3>
            <p>If you can't connect to a service running in your container:</p>
            <ol>
                <li>Ensure you've published the port with <code>-p host_port:container_port</code></li>
                <li>Verify the service is running and listening on the expected port: <code>docker exec container_id netstat -tulpn</code></li>
                <li>Check if the service is binding to 0.0.0.0 (all interfaces) rather than just 127.0.0.1</li>
                <li>Ensure your firewall isn't blocking the port</li>
            </ol>
            
            <h3>Disk Space Issues</h3>
            <p>Docker can consume significant disk space over time:</p>
            <ol>
                <li>View disk usage: <code>docker system df</code></li>
                <li>Clean up resources: <code>docker system prune</code></li>
                <li>Remove unused images: <code>docker image prune</code></li>
                <li>Remove unused volumes: <code>docker volume prune</code></li>
            </ol>
            
            <h3>Build Failures</h3>
            <p>If your image build fails:</p>
            <ol>
                <li>Review the build output for specific error messages</li>
                <li>Ensure you have proper network connectivity if your build needs to download packages</li>
                <li>Try building with the <code>--no-cache</code> option to start fresh</li>
                <li>Build interactively up to the failing step to troubleshoot</li>
            </ol>
            
            <h3>Permission Issues</h3>
            <p>Docker containers often run as root by default, which can cause permission issues with mounted volumes:</p>
            <ol>
                <li>Specify a user when running containers: <code>docker run -u $(id -u):$(id -g) ...</code></li>
                <li>Set appropriate file permissions on the host before mounting</li>
                <li>Use a custom user in your Dockerfile: <code>USER myuser</code></li>
            </ol>
        </section>

        <section>
            <h2>Docker Security Best Practices</h2>
            
            <p>Security is crucial when using Docker in production environments. Here are some best practices to keep your containers secure:</p>
            
            <h3>Image Security</h3>
            <ul>
                <li><strong>Use official or verified images</strong> from trusted sources</li>
                <li><strong>Scan images for vulnerabilities</strong> using tools like Docker Scan, Trivy, or Clair</li>
                <li><strong>Use specific version tags</strong> instead of "latest" to prevent unexpected changes</li>
                <li><strong>Keep base images updated</strong> with security patches</li>
            </ul>
            
            <h3>Container Security</h3>
            <ul>
                <li><strong>Run containers as non-root users</strong> whenever possible</li>
                <li><strong>Use read-only file systems</strong> where appropriate: <code>docker run --read-only ...</code></li>
                <li><strong>Limit container resources</strong> with flags like <code>--memory</code> and <code>--cpu-shares</code></li>
                <li><strong>Never store secrets in container images</strong>; use environment variables or secret management tools</li>
            </ul>
            
            <h3>Network Security</h3>
            <ul>
                <li><strong>Use custom networks</strong> to isolate container communications</li>
                <li><strong>Expose only necessary ports</strong></li>
                <li><strong>Use TLS</strong> for Docker daemon connections</li>
                <li><strong>Implement network policies</strong> to control traffic between containers</li>
            </ul>
            
            <h3>Dockerfile Security</h3>
            <pre><code># Create a non-root user
RUN adduser --disabled-password --gecos "" myuser

# Set ownership of app files
COPY --chown=myuser:myuser . /app

# Switch to non-root user
USER myuser

# Use specific versions of packages
RUN pip install flask==2.0.1 gunicorn==20.1.0

# Minimize installed packages
RUN apt-get update && \
    apt-get install --no-install-recommends -y only-what-you-need && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*</code></pre>
        </section>

        <section>
            <h2>Preparing for Docker Compose</h2>
            
            <p>While today we've focused on single-container applications, most real-world projects require multiple interconnected containers. Tomorrow, we'll explore Docker Compose, which simplifies multi-container application management.</p>
            
            <p>Docker Compose allows you to define your entire application stack in a single YAML file, including:</p>
            <ul>
                <li>Services (containers)</li>
                <li>Networks</li>
                <li>Volumes</li>
                <li>Environment variables</li>
                <li>Dependencies between services</li>
            </ul>
            
            <p>Here's a preview of what we'll cover:</p>
            <pre><code># docker-compose.yml example
version: '3'

services:
  web:
    build: .
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    environment:
      - FLASK_ENV=development
    depends_on:
      - db
  
  db:
    image: postgres:14
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=secretpassword

volumes:
  postgres_data:</code></pre>
        </section>

        <section>
            <h2>Practice Exercise: Your First Docker Container</h2>
            
            <p>Let's apply what we've learned with a hands-on exercise:</p>
            
            <h3>Exercise: Dockerize a Simple Python Application</h3>
            
            <h4>Part 1: Create a Python Application</h4>
            <ol>
                <li>Create a new directory for your project: <code>mkdir docker-exercise</code></li>
                <li>Navigate to the directory: <code>cd docker-exercise</code></li>
                <li>Create a simple Python file named <code>app.py</code>:
                <pre><code>from flask import Flask, render_template
import os
import socket

app = Flask(__name__)

@app.route('/')
def hello():
    hostname = socket.gethostname()
    return render_template('index.html', hostname=hostname)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)</code></pre>
                </li>
                <li>Create a <code>templates</code> directory: <code>mkdir templates</code></li>
                <li>Create a template file <code>templates/index.html</code>:
                <pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Docker Exercise&lt;/title&gt;
    &lt;style&gt;
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
            text-align: center;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: #f5f5f5;
            padding: 20px;
            border-radius: 10px;
        }
        h1 {
            color: #333;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class="container"&gt;
        &lt;h1&gt;Hello from Docker!&lt;/h1&gt;
        &lt;p&gt;This page is served from a Docker container.&lt;/p&gt;
        &lt;p&gt;Container hostname: {{ hostname }}&lt;/p&gt;
    &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre>
                </li>
                <li>Create a <code>requirements.txt</code> file:
                <pre><code>flask==2.0.1</code></pre>
                </li>
            </ol>
            
            <h4>Part 2: Create a Dockerfile</h4>
            <ol>
                <li>Create a <code>Dockerfile</code> in the project directory:
                <pre><code>FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["python", "app.py"]</code></pre>
                </li>
                <li>Create a <code>.dockerignore</code> file:
                <pre><code>__pycache__/
*.pyc
*.pyo
*.pyd
.git/
.idea/
.vscode/
venv/</code></pre>
                </li>
            </ol>
            
            <h4>Part 3: Build and Run the Container</h4>
            <ol>
                <li>Build the Docker image: <code>docker build -t python-flask-app .</code></li>
                <li>Run the container: <code>docker run -p 5000:5000 --name flask-container python-flask-app</code></li>
                <li>Open your browser and visit <code>http://localhost:5000</code> to see your application running</li>
                <li>Stop the container with Ctrl+C or from another terminal: <code>docker stop flask-container</code></li>
            </ol>
            
            <h4>Part 4: Experiment with Docker Commands</h4>
            <ol>
                <li>Run the container in detached mode: <code>docker run -d -p 5000:5000 --name flask-container python-flask-app</code></li>
                <li>Check container logs: <code>docker logs flask-container</code></li>
                <li>Execute a command in the running container: <code>docker exec -it flask-container ls -la</code></li>
                <li>Get a shell in the container: <code>docker exec -it flask-container bash</code></li>
                <li>Stop the container: <code>docker stop flask-container</code></li>
                <li>Remove the container: <code>docker rm flask-container</code></li>
            </ol>
            
            <h4>Bonus Challenge: Modify the Application</h4>
            <ol>
                <li>Modify the app to display the current time along with the hostname</li>
                <li>Rebuild the image with a new tag: <code>docker build -t python-flask-app:v2 .</code></li>
                <li>Run the new version: <code>docker run -p 5000:5000 python-flask-app:v2</code></li>
                <li>Verify your changes in the browser</li>
            </ol>
        </section>

        <section>
            <h2>Resources for Further Learning</h2>
            
            <h3>Official Documentation</h3>
            <ul>
                <li><a href="https://docs.docker.com/" target="_blank">Docker Documentation</a></li>
                <li><a href="https://docs.docker.com/get-started/" target="_blank">Docker Get Started Guide</a></li>
                <li><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/" target="_blank">Dockerfile Best Practices</a></li>
            </ul>
            
            <h3>Tutorials and Courses</h3>
            <ul>
                <li><a href="https://www.docker.com/101-tutorial" target="_blank">Docker 101 Tutorial</a></li>
                <li><a href="https://www.katacoda.com/courses/docker" target="_blank">Katacoda Docker Playground</a></li>
                <li><a href="https://training.play-with-docker.com/" target="_blank">Play with Docker Classroom</a></li>
            </ul>
            
            <h3>Books</h3>
            <ul>
                <li>"Docker Deep Dive" by Nigel Poulton</li>
                <li>"Docker in Practice" by Ian Miell and Aidan Hobson Sayers</li>
                <li>"Docker for Developers" by Richard Bullington-McGuire, Andrew K. Dennis, and Michael Schwartz</li>
            </ul>
            
            <h3>Community Resources</h3>
            <ul>
                <li><a href="https://forums.docker.com/" target="_blank">Docker Forums</a></li>
                <li><a href="https://stackoverflow.com/questions/tagged/docker" target="_blank">Stack Overflow Docker Tag</a></li>
                <li><a href="https://www.reddit.com/r/docker/" target="_blank">Docker Subreddit</a></li>
            </ul>
        </section>

        <section>
            <h2>Conclusion</h2>
            
            <p>Today, we've explored the fundamentals of Docker and containerization. We've learned how to create, run, and manage containers, which form the foundation of modern application development and deployment.</p>
            
            <p>Docker addresses many common development challenges by providing consistent environments, dependency isolation, and efficient resource utilization. These benefits are particularly valuable for Python web developers who need to manage complex application stacks.</p>
            
            <p>Tomorrow, we'll build on these concepts as we dive into Docker Compose, which will allow us to define and run multi-container applications. This will bring us one step closer to developing complete web applications with Python, databases, and other services working together seamlessly.</p>
            
            <h3>Key Takeaways</h3>
            <ul>
                <li>Docker containers provide a consistent environment from development to production</li>
                <li>Images are blueprints for containers, defined by Dockerfiles</li>
                <li>Containers are isolated, portable runtime environments</li>
                <li>Docker Hub provides a repository of pre-built images</li>
                <li>Volumes provide persistent storage for containers</li>
                <li>Networking allows containers to communicate with each other and the outside world</li>
            </ul>
            
            <h3>Assignment</h3>
            <p>Complete the practice exercise described above and be prepared to share your experience tomorrow. Try extending the exercise by:</p>
            <ol>
                <li>Adding environment variables to configure your application</li>
                <li>Creating a volume to persist data across container restarts</li>
                <li>Using a custom network to connect multiple containers</li>
            </ol>
            
            <p>In tomorrow's session, we'll see how Docker Compose simplifies these tasks by defining your entire application stack in a single configuration file.</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2025 Full Stack Python Web Development Course</p>
    </footer>
</body>
</html>
